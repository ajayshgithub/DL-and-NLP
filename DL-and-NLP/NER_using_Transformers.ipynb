{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7914996430_0.4835089337245446"
      },
      "execution_count": null,
      "source": [
        "!!pip install pytorch-transformers"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7914996430_0.17767204569324102"
      },
      "execution_count": 1,
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\nfrom transformers import pipeline\n\ntokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\nmodel = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n\nnlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\nexample = \"My name is Wolfgang and I live in Berlin\"\n\nner_results = nlp(example)\nprint(ner_results)\n"
      ],
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99318b48cf5e438ab97c848ce7b4e8fc"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b69f0da238524cdc994cd4a00bfea0b4"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9fe5a634699431baee0ad5b326b74fb"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18818cca84da4056a6c6b7e735935acf"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e16b2c7421e3401a846da255e1a0bd7a"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79c874cc9d1841858ba147750e879773"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n[{'entity': 'B-PER', 'score': 0.9990139, 'index': 4, 'word': 'Wolfgang', 'start': 11, 'end': 19}, {'entity': 'B-LOC', 'score': 0.999645, 'index': 9, 'word': 'Berlin', 'start': 34, 'end': 40}]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7914996430_0.7383805356949464"
      },
      "execution_count": 2,
      "source": [
        "# Example usage with provided example sentences\nexample_sentences = [\n    \"Elon Musk is the CEO of SpaceX and Tesla.\",\n    \"The Eiffel Tower is located in Paris, France.\",\n    \"Barack Obama served as the President of the United States from 2009 to 2017.\",\n    \"The Mona Lisa, painted by Leonardo da Vinci, hangs in the Louvre Museum.\",\n    \"Amazon, headquartered in Seattle, is one of the largest e-commerce companies in the world.\",\n    \"Albert Einstein, born in Germany, was a renowned physicist known for his theory of relativity.\",\n    \"The Great Wall of China stretches over 13,000 miles across northern China.\",\n    \"J.K. Rowling is the author of the Harry Potter series.\",\n    \"The Nile River is the longest river in the world, flowing through several countries in Africa.\",\n    \"Bill Gates, co-founder of Microsoft, is a prominent philanthropist.\"\n]"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7914996430_0.3050128336357074"
      },
      "execution_count": 3,
      "source": [
        "for sentence in example_sentences:\n    print(\"\\nProcessing sentence:\", sentence)\n    ner_pred = nlp(sentence)\n    print(ner_pred)"
      ],
      "outputs": [
        {
          "name": "stdout",
          "text": "\nProcessing sentence: Elon Musk is the CEO of SpaceX and Tesla.\n[{'entity': 'B-PER', 'score': 0.9940339, 'index': 1, 'word': 'El', 'start': 0, 'end': 2}, {'entity': 'B-PER', 'score': 0.802104, 'index': 2, 'word': '##on', 'start': 2, 'end': 4}, {'entity': 'I-PER', 'score': 0.9985234, 'index': 3, 'word': 'Mu', 'start': 5, 'end': 7}, {'entity': 'I-PER', 'score': 0.9736921, 'index': 4, 'word': '##sk', 'start': 7, 'end': 9}, {'entity': 'B-ORG', 'score': 0.999438, 'index': 9, 'word': 'Space', 'start': 24, 'end': 29}, {'entity': 'I-ORG', 'score': 0.9989631, 'index': 10, 'word': '##X', 'start': 29, 'end': 30}, {'entity': 'B-ORG', 'score': 0.998966, 'index': 12, 'word': 'Te', 'start': 35, 'end': 37}, {'entity': 'I-ORG', 'score': 0.9966664, 'index': 13, 'word': '##sla', 'start': 37, 'end': 40}]\n\nProcessing sentence: The Eiffel Tower is located in Paris, France.\n[{'entity': 'B-LOC', 'score': 0.96584433, 'index': 2, 'word': 'E', 'start': 4, 'end': 5}, {'entity': 'B-LOC', 'score': 0.4985719, 'index': 3, 'word': '##iff', 'start': 5, 'end': 8}, {'entity': 'B-LOC', 'score': 0.8683109, 'index': 4, 'word': '##el', 'start': 8, 'end': 10}, {'entity': 'I-LOC', 'score': 0.9852143, 'index': 5, 'word': 'Tower', 'start': 11, 'end': 16}, {'entity': 'B-LOC', 'score': 0.9994931, 'index': 9, 'word': 'Paris', 'start': 31, 'end': 36}, {'entity': 'B-LOC', 'score': 0.99946934, 'index': 11, 'word': 'France', 'start': 38, 'end': 44}]\n\nProcessing sentence: Barack Obama served as the President of the United States from 2009 to 2017.\n[{'entity': 'B-PER', 'score': 0.9994611, 'index': 1, 'word': 'Barack', 'start': 0, 'end': 6}, {'entity': 'I-PER', 'score': 0.9994436, 'index': 2, 'word': 'Obama', 'start': 7, 'end': 12}, {'entity': 'B-LOC', 'score': 0.99974436, 'index': 9, 'word': 'United', 'start': 44, 'end': 50}, {'entity': 'I-LOC', 'score': 0.9992428, 'index': 10, 'word': 'States', 'start': 51, 'end': 57}]\n\nProcessing sentence: The Mona Lisa, painted by Leonardo da Vinci, hangs in the Louvre Museum.\n[{'entity': 'B-MISC', 'score': 0.95826197, 'index': 2, 'word': 'Mona', 'start': 4, 'end': 8}, {'entity': 'I-MISC', 'score': 0.99185306, 'index': 3, 'word': 'Lisa', 'start': 9, 'end': 13}, {'entity': 'B-PER', 'score': 0.99919885, 'index': 7, 'word': 'Leonardo', 'start': 26, 'end': 34}, {'entity': 'I-PER', 'score': 0.99443996, 'index': 8, 'word': 'da', 'start': 35, 'end': 37}, {'entity': 'I-PER', 'score': 0.9905007, 'index': 9, 'word': 'Vinci', 'start': 38, 'end': 43}, {'entity': 'B-LOC', 'score': 0.9236846, 'index': 14, 'word': 'Lou', 'start': 58, 'end': 61}, {'entity': 'B-LOC', 'score': 0.8678453, 'index': 15, 'word': '##vre', 'start': 61, 'end': 64}, {'entity': 'I-LOC', 'score': 0.9798708, 'index': 16, 'word': 'Museum', 'start': 65, 'end': 71}]\n\nProcessing sentence: Amazon, headquartered in Seattle, is one of the largest e-commerce companies in the world.\n[{'entity': 'B-ORG', 'score': 0.99894446, 'index': 1, 'word': 'Amazon', 'start': 0, 'end': 6}, {'entity': 'B-LOC', 'score': 0.99808323, 'index': 5, 'word': 'Seattle', 'start': 25, 'end': 32}]\n\nProcessing sentence: Albert Einstein, born in Germany, was a renowned physicist known for his theory of relativity.\n[{'entity': 'B-PER', 'score': 0.99961805, 'index': 1, 'word': 'Albert', 'start': 0, 'end': 6}, {'entity': 'I-PER', 'score': 0.99851435, 'index': 2, 'word': 'Einstein', 'start': 7, 'end': 15}, {'entity': 'B-LOC', 'score': 0.99934405, 'index': 6, 'word': 'Germany', 'start': 25, 'end': 32}]\n\nProcessing sentence: The Great Wall of China stretches over 13,000 miles across northern China.\n[{'entity': 'B-LOC', 'score': 0.9971097, 'index': 2, 'word': 'Great', 'start': 4, 'end': 9}, {'entity': 'I-LOC', 'score': 0.99734515, 'index': 3, 'word': 'Wall', 'start': 10, 'end': 14}, {'entity': 'I-LOC', 'score': 0.99576676, 'index': 4, 'word': 'of', 'start': 15, 'end': 17}, {'entity': 'I-LOC', 'score': 0.993214, 'index': 5, 'word': 'China', 'start': 18, 'end': 23}, {'entity': 'B-LOC', 'score': 0.99981064, 'index': 14, 'word': 'China', 'start': 68, 'end': 73}]\n\nProcessing sentence: J.K. Rowling is the author of the Harry Potter series.\n[{'entity': 'B-PER', 'score': 0.99934167, 'index': 1, 'word': 'J', 'start': 0, 'end': 1}, {'entity': 'B-PER', 'score': 0.9935237, 'index': 2, 'word': '.', 'start': 1, 'end': 2}, {'entity': 'I-PER', 'score': 0.9908071, 'index': 3, 'word': 'K', 'start': 2, 'end': 3}, {'entity': 'I-PER', 'score': 0.7935766, 'index': 4, 'word': '.', 'start': 3, 'end': 4}, {'entity': 'I-PER', 'score': 0.9991347, 'index': 5, 'word': 'Row', 'start': 5, 'end': 8}, {'entity': 'I-PER', 'score': 0.9966258, 'index': 6, 'word': '##ling', 'start': 8, 'end': 12}, {'entity': 'B-MISC', 'score': 0.9891699, 'index': 12, 'word': 'Harry', 'start': 34, 'end': 39}, {'entity': 'I-MISC', 'score': 0.9953685, 'index': 13, 'word': 'Potter', 'start': 40, 'end': 46}]\n\nProcessing sentence: The Nile River is the longest river in the world, flowing through several countries in Africa.\n[{'entity': 'B-LOC', 'score': 0.99363744, 'index': 2, 'word': 'Nile', 'start': 4, 'end': 8}, {'entity': 'I-LOC', 'score': 0.9933067, 'index': 3, 'word': 'River', 'start': 9, 'end': 14}, {'entity': 'B-LOC', 'score': 0.9997359, 'index': 17, 'word': 'Africa', 'start': 87, 'end': 93}]\n\nProcessing sentence: Bill Gates, co-founder of Microsoft, is a prominent philanthropist.\n[{'entity': 'B-PER', 'score': 0.99961346, 'index': 1, 'word': 'Bill', 'start': 0, 'end': 4}, {'entity': 'I-PER', 'score': 0.99969554, 'index': 2, 'word': 'Gates', 'start': 5, 'end': 10}, {'entity': 'B-ORG', 'score': 0.9980761, 'index': 8, 'word': 'Microsoft', 'start': 26, 'end': 35}]\n",
          "output_type": "stream"
        }
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 2
}