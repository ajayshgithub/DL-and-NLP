{"cells": [{"cell_type": "code", "metadata": {"id": "0_0.19505591316221094"}, "execution_count": 1, "source": ["import torch\nimport torch.nn as nn\nimport torch.nn.functional as f"], "outputs": [{"name": "stdout", "text": ["\n"], "output_type": "stream"}]}, {"cell_type": "code", "metadata": {"id": "0_0.13038351926249736"}, "execution_count": 5, "source": ["# Model inherit from nn.Module\nclass Model(nn.Module): \n\n    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n        # how many layers\n        # instantiate the inherited Module by calling its own init method\n        super().__init__() # this essentially instantiates the class we are inheriting from\n        self.fc1 = nn.Linear(in_features,h1)\n        self.fc2 = nn.Linear(h1,h2)\n        self.out = nn.Linear(h2,out_features)\n\n    # Input layer (4 features)--> h1 (N1 Neurons) --> h2 (N2 Neurons) --> Output (3 classes)\n\n    def forward(self,x):\n        # F.relu is activation function\n        # passing features x into fc layers and then the o/p thru' the activation function\n        x = f.relu(self.fc1(x)) \n        x = f.relu(self.fc2(x))\n        x = self.out(x)\n\n        return x\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.008090743150739765"}, "execution_count": 6, "source": ["torch.manual_seed(32)\nmodel = Model()"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.7809786669036649"}, "execution_count": 8, "source": ["import pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv(@SYS.DATASANDBOX_PATH + '4031682022/Repo/Iris.csv')"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.8493141068917047"}, "execution_count": 9, "source": ["df.head()"], "outputs": [{"data": {"text/plain": ["   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n0   1            5.1           3.5            1.4           0.2  Iris-setosa\n1   2            4.9           3.0            1.4           0.2  Iris-setosa\n2   3            4.7           3.2            1.3           0.2  Iris-setosa\n3   4            4.6           3.1            1.5           0.2  Iris-setosa\n4   5            5.0           3.6            1.4           0.2  Iris-setosa"], "text/html": ["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>SepalLengthCm</th>\n      <th>SepalWidthCm</th>\n      <th>PetalLengthCm</th>\n      <th>PetalWidthCm</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}, "metadata": {}, "execution_count": 10, "output_type": "execute_result"}]}, {"cell_type": "code", "metadata": {"id": "0_0.26180164401000794"}, "execution_count": 12, "source": ["from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\ndf['Species'] = le.fit_transform(df.Species.values);"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.9532317437396747"}, "execution_count": 15, "source": ["# X = df.drop('target', axis=1)\n# y = df['target']\nX = df.drop('Species', axis=1)\ny = df['Species']"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.4473329510212971"}, "execution_count": 16, "source": ["X_v = X.values\ny_v = y.values"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.8009988421337553"}, "execution_count": 17, "source": ["from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_v,y_v,test_size=0.2,random_state=33)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.7837135154605193"}, "execution_count": 18, "source": ["X_train = torch.FloatTensor(X_train)\nX_test = torch.FloatTensor(X_test)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "4988685938_0.24252688450526794"}, "execution_count": 23, "source": ["X_train.shape"], "outputs": [{"data": {"text/plain": "torch.Size([120, 5])"}, "metadata": {}, "execution_count": 24, "output_type": "execute_result"}]}, {"cell_type": "code", "metadata": {"id": "0_0.7126185538965755"}, "execution_count": 19, "source": ["# in pytorch if you use cross entropy loss we don't need to do one-hot encoding for multiclass scenario\ny_train = torch.LongTensor(y_train)\ny_test = torch.LongTensor(y_test)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "4988685938_0.5554647089653544"}, "execution_count": 24, "source": ["y_train.shape"], "outputs": [{"data": {"text/plain": "torch.Size([120])"}, "metadata": {}, "execution_count": 25, "output_type": "execute_result"}]}, {"cell_type": "code", "metadata": {"id": "0_0.16188506397550673"}, "execution_count": 20, "source": ["criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=0.01)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.11840635599362259"}, "execution_count": 21, "source": ["model.parameters"], "outputs": [{"data": {"text/plain": "<bound method Module.parameters of Model(\n  (fc1): Linear(in_features=4, out_features=8, bias=True)\n  (fc2): Linear(in_features=8, out_features=9, bias=True)\n  (out): Linear(in_features=9, out_features=3, bias=True)\n)>"}, "metadata": {}, "execution_count": 22, "output_type": "execute_result"}]}, {"cell_type": "code", "metadata": {"id": "0_0.057390478235122444"}, "execution_count": 22, "source": ["epochs = 100\nlosses = []\n\nfor i in range(epochs):\n\n  # Forward and get a prediction\n  y_pred = model.forward(X_train)\n\n  # Calculate Loss /Error\n  loss = criterion(y_pred, y_train)\n\n  losses.append(loss)\n\n  if i%10==0:\n    print(f'Epoch {i} and Loss is: {loss}')\n\n  optimizer.zero_grad()\n  loss.backward()\n  optimizer.step()"], "outputs": [{"traceback": ["---------------------------------------------------------------------------", "RuntimeError                              Traceback (most recent call last)", "Cell In[23], line 7\n      2 losses = []\n      4 for i in range(epochs):\n      5 \n      6   # Forward and get a prediction\n----> 7   y_pred = model.forward(X_train)\n      9   # Calculate Loss /Error\n     10   loss = criterion(y_pred, y_train)\n", "Cell In[6], line 17, in Model.forward(self, x)\n     14 def forward(self,x):\n     15     # F.relu is activation function\n     16     # passing features x into fc layers and then the o/p thru' the activation function\n---> 17     x = f.relu(self.fc1(x)) \n     18     x = f.relu(self.fc2(x))\n     19     x = self.out(x)\n", "File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501, in Module._call_impl(self, *args, **kwargs)\n   1496 # If we don't have any hooks, we want to skip the rest of the logic in\n   1497 # this function, and just call forward.\n   1498 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n   1499         or _global_backward_pre_hooks or _global_backward_hooks\n   1500         or _global_forward_hooks or _global_forward_pre_hooks):\n-> 1501     return forward_call(*args, **kwargs)\n   1502 # Do not call functions when jit is used\n   1503 full_backward_hooks, non_full_backward_hooks = [], []\n", "File /opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114, in Linear.forward(self, input)\n    113 def forward(self, input: Tensor) -> Tensor:\n--> 114     return F.linear(input, self.weight, self.bias)\n", "RuntimeError: mat1 and mat2 shapes cannot be multiplied (120x5 and 4x8)"], "ename": "RuntimeError", "evalue": "mat1 and mat2 shapes cannot be multiplied (120x5 and 4x8)", "output_type": "error"}]}, {"cell_type": "code", "metadata": {"id": "0_0.8333858321426479"}, "execution_count": null, "source": ["with torch.no_grad(): # deactivates the auto gradient engine\n  plt.plot(range(epochs),losses)\n  plt.ylabel('CROSS ENTROPY LOSS')\n  plt.xlabel('Epoch ')"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.13147995383432898"}, "execution_count": null, "source": ["with torch.no_grad():\n  y_eval = model.forward(X_test)\n  loss = criterion(y_eval, y_test)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.6211904790075178"}, "execution_count": null, "source": ["loss"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.9409485227891043"}, "execution_count": null, "source": ["correct = 0\n\nwith torch.no_grad():\n  for i, data in enumerate(X_test):\n    y_val = model.forward(data)\n    # print(f'{i+1}.)   {str(y_val)}   {y_test[i]}')\n    print(f'{i+1}.)   {str(y_val.argmax().item())}   {y_test[i]}')\n\n    if y_val.argmax().item() == y_test[i]:\n      correct += 1\n\nprint(f'We got {correct} correct')"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.7894270000752128"}, "execution_count": null, "source": ["model_scripted = torch.jit.script(model) # Export to TorchScript\nmodel_scripted.save('model_scripted.pth') # Save"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.5666316356423222"}, "execution_count": null, "source": ["model_j = torch.jit.load('model_scripted.pth')\nmodel_j.eval()"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.8041195379406403"}, "execution_count": null, "source": ["mystery_iris = torch.tensor([5.6,3.7,2.2,0.5])"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.9589240148928257"}, "execution_count": null, "source": ["with torch.no_grad():\n  print(model(mystery_iris))\n  print(model(mystery_iris).argmax().item())"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.42750541392557806"}, "execution_count": null, "source": ["with torch.no_grad():\n  # print(new_model(X_test))\n  # print(new_model(X_test).argmax())\n\n  for i, data in enumerate(model(X_test)):\n\n  # print(f'{i+1}.)   {str(y_val)}   {y_test[i]}')\n    print(f'{i+1}.)   {str(data.argmax().item())}')"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.8528608392692787"}, "execution_count": null, "source": ["# saves only weights and biases\ntorch.save(model.state_dict(),'my_iris_model.pt') "], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.6160689790613236"}, "execution_count": null, "source": ["new_model = Model() # does not know W or B\nnew_model.load_state_dict(torch.load('my_iris_model.pt'))"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.3510626695292076"}, "execution_count": null, "source": ["new_model.eval()"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.043596483419249044"}, "execution_count": null, "source": ["torch.save(model,'my_iris_model.pth') "], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.08053317965077378"}, "execution_count": null, "source": ["new_model = torch.load('my_iris_model.pth')"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.19297196661206728"}, "execution_count": null, "source": ["new_model.eval()"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.5131570876785603"}, "execution_count": null, "source": ["mystery_iris = torch.tensor([5.6,3.7,2.2,0.5])"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.8795886426600996"}, "execution_count": null, "source": ["fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,7))\nfig.tight_layout()\n\nplots = [(0,1),(2,3),(0,2),(1,3)]\ncolors = ['b', 'r', 'g']\nlabels = ['Iris setosa','Iris virginica','Iris versicolor']\n\nfor i, ax in enumerate(axes.flat):\n    for j in range(3):\n        x = df.columns[plots[i][0]]\n        y = df.columns[plots[i][1]]\n        ax.scatter(df[df['species']==j][x], df[df['species']==j][y], color=colors[j])\n        ax.set(xlabel=x, ylabel=y)\n\n    # Add a plot for our mystery iris:\n    ax.scatter(mystery_iris[plots[i][0]], mystery_iris[plots[i][1]], color='y')\n\nfig.legend(labels=labels, loc=3, bbox_to_anchor=(1.0,0.85))\nplt.show()"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.15422097083100805"}, "execution_count": null, "source": ["with torch.no_grad():\n  print(new_model(mystery_iris))\n  print(new_model(mystery_iris).argmax().item())"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.6152580212043526"}, "execution_count": null, "source": ["data_list = []\nwith torch.no_grad():\n  # print(new_model(X_test))\n  # print(new_model(X_test).argmax())\n\n  for i, data in enumerate(new_model(X_test)):\n\n  # print(f'{i+1}.)   {str(y_val)}   {y_test[i]}')\n    # print(f'{i+1}.)   {str(data.argmax().item())}')\n    data_list.append(data.argmax().item())\ndata_list"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.8446561557970371"}, "execution_count": null, "source": ["data_series = pd.Series(data_list) "], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.0015050498048911898"}, "execution_count": null, "source": ["X_test_d = pd.DataFrame(X_test, columns=X.columns)\nX_test_d"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.27481050696286036"}, "execution_count": null, "source": ["pred = pd.concat([X_test_d, data_series], axis=1)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.4896518268554415"}, "execution_count": null, "source": ["pred.rename({0: 'predictions'}, axis=1, inplace=True)\npred"], "outputs": []}], "metadata": {}, "nbformat": 4, "nbformat_minor": 2}