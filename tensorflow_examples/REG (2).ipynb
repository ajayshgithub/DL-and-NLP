{"cells": [{"cell_type": "markdown", "metadata": {"id": "0_0.344605867340136"}, "execution_count": null, "source": ["##### Copyright 2018 The TensorFlow Authors."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.6775051075613847"}, "execution_count": null, "source": ["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.8778921467985454"}, "execution_count": null, "source": ["#@title MIT License\n#\n# Copyright (c) 2017 Fran\u00e7ois Chollet\n#\n# Permission is hereby granted, free of charge, to any person obtaining a\n# copy of this software and associated documentation files (the \"Software\"),\n# to deal in the Software without restriction, including without limitation\n# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n# and/or sell copies of the Software, and to permit persons to whom the\n# Software is furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n# DEALINGS IN THE SOFTWARE."], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "0_0.7845807695250391"}, "execution_count": null, "source": ["# Basic regression: Predict fuel efficiency"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "0_0.059228200142139587"}, "execution_count": null, "source": ["<table class=\"tfo-notebook-buttons\" align=\"left\">\n  <td>\n    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/regression\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n  </td>\n  <td>\n    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/regression.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n  </td>\n  <td>\n    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/regression.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n  </td>\n  <td>\n    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/keras/regression.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n  </td>\n</table>"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "0_0.5145223458603296"}, "execution_count": null, "source": ["In a *regression* problem, the aim is to predict the output of a continuous value, like a price or a probability. Contrast this with a *classification* problem, where the aim is to select a class from a list of classes (for example, where a picture contains an apple or an orange, recognizing which fruit is in the picture).\n\nThis tutorial uses the classic [Auto MPG](https://archive.ics.uci.edu/ml/datasets/auto+mpg) dataset and demonstrates how to build models to predict the fuel efficiency of the late-1970s and early 1980s automobiles. To do this, you will provide the models with a description of many automobiles from that time period. This description includes attributes like cylinders, displacement, horsepower, and weight.\n\nThis example uses the Keras API. (Visit the Keras [tutorials](https://www.tensorflow.org/tutorials/keras) and [guides](https://www.tensorflow.org/guide/keras) to learn more.)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.5210562990934926"}, "execution_count": 1, "source": ["# Use seaborn for pairplot.\n!!pip install -q seaborn"], "outputs": [{"traceback": ["---------------------------------------------------------------------------", "KeyboardInterrupt                         Traceback (most recent call last)", "Cell In[1], line 1\n----> 1 get_ipython().run_cell_magic('bash', '', 'exec >/dev/null\\nexec 2>/dev/null\\npip install -q tensorflow\\n')\n", "File /opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2478, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)\n   2476 with self.builtin_trap:\n   2477     args = (magic_arg_s, cell)\n-> 2478     result = fn(*args, **kwargs)\n   2480 # The code below prevents the output from being displayed\n   2481 # when using magics with decodator @output_can_be_silenced\n   2482 # when the last Python token in the expression is a ';'.\n   2483 if getattr(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, False):\n", "File ~/.ipython/profile_default/startup/startup.py:59, in bash(line, cell)\n     57     print(output.decode())\n     58 else:\n---> 59     process = subprocess.run(cell, shell=True, capture_output=True)\n     60     print(process.stdout.decode().strip())\n     61 del subprocess\n", "File /opt/conda/lib/python3.10/subprocess.py:505, in run(input, capture_output, timeout, check, *popenargs, **kwargs)\n    503 with Popen(*popenargs, **kwargs) as process:\n    504     try:\n--> 505         stdout, stderr = process.communicate(input, timeout=timeout)\n    506     except TimeoutExpired as exc:\n    507         process.kill()\n", "File /opt/conda/lib/python3.10/subprocess.py:1154, in Popen.communicate(self, input, timeout)\n   1151     endtime = None\n   1153 try:\n-> 1154     stdout, stderr = self._communicate(input, endtime, timeout)\n   1155 except KeyboardInterrupt:\n   1156     # https://bugs.python.org/issue25942\n   1157     # See the detailed comment in .wait().\n   1158     if timeout is not None:\n", "File /opt/conda/lib/python3.10/subprocess.py:2047, in Popen._communicate(self, input, endtime, orig_timeout)\n   2044                     key.fileobj.close()\n   2045                 self._fileobj2output[key.fileobj].append(data)\n-> 2047 self.wait(timeout=self._remaining_time(endtime))\n   2049 # All data exchanged.  Translate lists into strings.\n   2050 if stdout is not None:\n", "File /opt/conda/lib/python3.10/subprocess.py:1209, in Popen.wait(self, timeout)\n   1207     endtime = _time() + timeout\n   1208 try:\n-> 1209     return self._wait(timeout=timeout)\n   1210 except KeyboardInterrupt:\n   1211     # https://bugs.python.org/issue25942\n   1212     # The first keyboard interrupt waits briefly for the child to\n   1213     # exit under the common assumption that it also received the ^C\n   1214     # generated SIGINT and will exit rapidly.\n   1215     if timeout is not None:\n", "File /opt/conda/lib/python3.10/subprocess.py:1959, in Popen._wait(self, timeout)\n   1957 if self.returncode is not None:\n   1958     break  # Another thread waited.\n-> 1959 (pid, sts) = self._try_wait(0)\n   1960 # Check the pid and loop as waitpid has been known to\n   1961 # return 0 even without WNOHANG in odd situations.\n   1962 # http://bugs.python.org/issue14396.\n   1963 if pid == self.pid:\n", "File /opt/conda/lib/python3.10/subprocess.py:1917, in Popen._try_wait(self, wait_flags)\n   1915 \"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\n   1916 try:\n-> 1917     (pid, sts) = os.waitpid(self.pid, wait_flags)\n   1918 except ChildProcessError:\n   1919     # This happens if SIGCLD is set to be ignored or waiting\n   1920     # for child processes has otherwise been disabled for our\n   1921     # process.  This child is dead, we can't get the status.\n   1922     pid = self.pid\n", "KeyboardInterrupt: "], "ename": "KeyboardInterrupt", "evalue": "", "output_type": "error"}]}, {"cell_type": "code", "metadata": {"id": "0_0.5323043533450458"}, "execution_count": 0, "source": ["import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n# Make NumPy printouts easier to read.\nnp.set_printoptions(precision=3, suppress=True)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.5601754795084497"}, "execution_count": null, "source": ["import tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nprint(tf.__version__)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "0_0.11695839223523019"}, "execution_count": null, "source": ["## The Auto MPG dataset\n\nThe dataset is available from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/).\n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "0_0.2791991037930459"}, "execution_count": null, "source": ["### Get the data\nFirst download and import the dataset using pandas:"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.005386514546021237"}, "execution_count": 1, "source": ["url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\ncolumn_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n                'Acceleration', 'Model Year', 'Origin']\n\nraw_dataset = pd.read_csv(url, names=column_names,\n                          na_values='?', comment='\\t',\n                          sep=' ', skipinitialspace=True)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "5260418185_0.40656945160539326"}, "execution_count": 4, "source": ["raw_dataset.to_csv(@SYS.DATASANDBOX_PATH + '4031682022/Data/mpg.csv',index=False)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.6946810445773222"}, "execution_count": null, "source": ["dataset = raw_dataset.copy()\ndataset.tail()"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.7631521764746465"}, "execution_count": null, "source": ["dataset.info()"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "0_0.9963060084387321"}, "execution_count": null, "source": ["### Clean the data\n\nThe dataset contains a few unknown values:"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.4229132309920749"}, "execution_count": null, "source": ["dataset.isna().sum()"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "0_0.6936546726409478"}, "execution_count": null, "source": ["Drop those rows to keep this initial tutorial simple:"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.6300411804647783"}, "execution_count": null, "source": ["dataset = dataset.dropna()"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "0_0.1522816671692664"}, "execution_count": null, "source": ["The `\"Origin\"` column is categorical, not numeric. So the next step is to one-hot encode the values in the column with [pd.get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html).\n\nNote: You can set up the `tf.keras.Model` to do this kind of transformation for you but that's beyond the scope of this tutorial. Check out the [Classify structured data using Keras preprocessing layers](../structured_data/preprocessing_layers.ipynb) or [Load CSV data](../load_data/csv.ipynb) tutorials for examples."], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "0_0.37554000670694543"}, "execution_count": null, "source": ["### Inspect the data\n\nReview the joint distribution of a few pairs of columns from the training set.\n\nThe top row suggests that the fuel efficiency (MPG) is a function of all the other parameters. The other rows indicate they are functions of each other."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.9760440285438936"}, "execution_count": null, "source": ["sns.pairplot(dataset[['MPG', 'Cylinders', 'Displacement', 'Weight']], diag_kind='kde')"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "0_0.3699791167379798"}, "execution_count": null, "source": ["Let's also check the overall statistics. Note how each feature covers a very different range:"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.444253783124118"}, "execution_count": null, "source": ["dataset.describe().transpose()"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "0_0.5219672520540606"}, "execution_count": null, "source": ["### Split features from labels\n\nSeparate the target value\u2014the \"label\"\u2014from the features. This label is the value that you will train the model to predict."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.6454906841311356"}, "execution_count": null, "source": ["# Define the MLP regressor model using TensorFlow\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPRegressor\n\n# Separate features (X) and target (y)\nX = dataset.drop(columns=['MPG'], inplace=False)  # Drop 'MPG' column from features\ny = dataset['MPG']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\ndef create_mlp_regressor(input_dim):\n    model = Sequential([\n        Dense(64, input_dim=input_dim, activation='relu'),\n        Dense(32, activation='relu'),\n        Dense(1)  # Output layer with 1 neuron for regression\n    ])\n    model.compile(optimizer='adam', loss='mse')  # Using mean squared error as loss for regression\n    return model\n\n# Create the sklearn pipeline\nmlp_regressor_pipeline = Pipeline([\n    ('scaler', StandardScaler()),         # Standardize features\n    ('mlp_regressor', MLPRegressor(hidden_layer_sizes=(64, 32), activation='relu', max_iter=1000))  # MLP regressor model\n])\n\n# Fit the pipeline to the training data\nmlp_regressor_pipeline.fit(X_train, y_train)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.44461945511967227"}, "execution_count": null, "source": ["# Evaluate the pipeline\ntrain_score = mlp_regressor_pipeline.score(X_train, y_train)\ntest_score = mlp_regressor_pipeline.score(X_test, y_test)\n\nprint(\"Training R^2 score:\", train_score)\nprint(\"Testing R^2 score:\", test_score)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.36055308982244205"}, "execution_count": null, "source": ["# Predict using the pipeline\ny_pred = mlp_regressor_pipeline.predict(X_test)"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.5601368709368881"}, "execution_count": null, "source": ["y_pred"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "5260418185_0.003499204377764631"}, "execution_count": null, "source": ["@SYS.DATASANDBOX_PATH + '4031682022/Data/mpg.csv'"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "5260418185_0.7091023975162394"}, "execution_count": 7, "source": ["# Split X_test into half and save 2nd half in files\n# This file will be called X_production\n# Read the data usng scriptrunner in pipeline( define read function )\n# use nfsdir/uploadfiles/1156"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0_0.9628846819248456"}, "execution_count": null, "source": ["from Notebook.DSNotebook.NotebookExecutor import NotebookExecutor\nnb = NotebookExecutor()\nsaved_model = nb.save_model(model = mlp_regressor_pipeline, modelName = 'tf_reg', modelType = 'ml', X = None, y = None, estimator_type='')\n#X and y are training datasets to get explainer dashboard.\n#estimator_type is to specify algorithm type i.e., classification and regression.\n#Only 'ml\u2019 models with tabular data as input will support in Explainer Dashboard.\n#Choose modelType = 'ml' for machine learning models, modelType = 'cv' for computer vision models and modelType = 'dp' for data transformation pickle files. \n#Provide \u2018column_headers\u2019 as a parameter if they have to be saved in the model.\n#If using custom layer in keras, use native save functionality from keras."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "5260418185_0.839835410253791"}, "execution_count": null, "source": ["def read_data():\n    df = pd.read_csv()\n    \n    \n    "], "outputs": []}], "metadata": {}, "nbformat": 4, "nbformat_minor": 2}